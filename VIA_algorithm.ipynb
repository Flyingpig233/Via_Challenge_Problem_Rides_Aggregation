{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('yellow_tripdata_2016-06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter records with pickup time before dropoff time\n",
    "df = df[pd.to_datetime(df['tpep_dropoff_datetime']) > pd.to_datetime(df['tpep_pickup_datetime'])]\n",
    "time_diff = pd.to_datetime(df['tpep_dropoff_datetime']) - pd.to_datetime(df['tpep_pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_duration in minutes\n",
    "df['trip_duration'] = [round(t.total_seconds()/60,0) for t in time_diff]\n",
    "\n",
    "# deal with records the trip duration is 0 min\n",
    "speed_calculate = df[df['trip_duration']!=0][['trip_duration','trip_distance']]\n",
    "\n",
    "# calculate average speed\n",
    "speed = sum(speed_calculate['trip_distance']/speed_calculate['trip_duration'])/speed_calculate.shape[0]\n",
    "print('Average driver speed is: ', speed,'/min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparedata for algorithm\n",
    "df2 = df[df['trip_duration']!=0][['tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "       'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]\n",
    "df2 = df2.sort_values(by=['tpep_pickup_datetime'])\n",
    "\n",
    "# 06/06/2016 - 06/12/2016  the first full week, Monday to Sunday\n",
    "df3 = df2[(df2['tpep_pickup_datetime']>='2016-06-06')& (df2['tpep_pickup_datetime']<'2016-06-13')]\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use longitude latitude to calculate distance (in miles)\n",
    "EARTH_REDIUS = 3958.8\n",
    "def rad(d):\n",
    "    return d * math.pi / 180.0\n",
    "\n",
    "def getDistance(lat1, lng1, lat2, lng2):\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * math.asin(math.sqrt(math.pow(math.sin(a/2), 2) + math.cos(radLat1) * math.cos(radLat2) * math.pow(math.sin(b/2), 2)))\n",
    "    s = s * EARTH_REDIUS\n",
    "    return s\n",
    "\n",
    "# not equal to the meter records on vehicles\n",
    "def getManhattanDistance(lat1, lng1, lat2, lng2):\n",
    "    return getDistance(lat1,lng1,lat2,lng1)+getDistance(lat2,lng1,lat2,lng2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use binary search to find the last passenger who meet the time requirement\n",
    "def findborder(b,l,r):\n",
    "    mid=(l+r)//2\n",
    "    while(r-l>1):\n",
    "        if b>=pktime[mid]:\n",
    "            l=mid\n",
    "        else:\n",
    "            r=mid\n",
    "        mid=(l+r)//2\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether (x,y) is in the rectangular with diagonal lining by (x1,y1),(x2,y2)\n",
    "def notthearea(x,y,x1,y1,x2,y2):\n",
    "    if (x>x1) & (x>x2):\n",
    "        return 1\n",
    "    if (x<x1) & (x<x2):\n",
    "        return 1\n",
    "    if (y<y1) & (y<y2):\n",
    "        return 1\n",
    "    if (y>y1) & (y>y2):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function: find qualified share-ride passenger for i th passenger ordered by pick-up time\n",
    "\n",
    "def find_share_rides_passenger(i):\n",
    "    \n",
    "    # ride information of i th passenger\n",
    "    pickup_time, dropoff_time, passenger_num, pickup_lon, pickup_lat, dropoff_lon, dropoff_lat = da.loc[i][:7]\n",
    "    dropoff_time_t=pd.to_datetime(dropoff_time)\n",
    "    \n",
    "    # find potential share-ride passenger who meets time requirement\n",
    "    bor=findborder(dropoff_time_t,i+1,n)\n",
    "    arr=da[i+1:bor]\n",
    "    \n",
    "    # find the first one who meets route requirement\n",
    "    for data in arr.itertuples():\n",
    "        j=data[0]\n",
    "        \n",
    "        # exceed the maximum passenger capacity or already get on other vehicles, move to next\n",
    "        # finished_passenger_tag is a global variable, indicae whether a massenger already gets on vehicle or not\n",
    "        if ((data.passenger_count+passenger_num>4) | (finished_passenger_tag[j]==1)):\n",
    "            continue\n",
    "            \n",
    "        # otherwise, check route requiement\n",
    "        pickup2_lon, pickup2_lat, dropoff2_lon, dropoff2_lat=data[4:8]\n",
    "        \n",
    "        # pick-up spot not qualified, move to next\n",
    "        if notthearea(pickup2_lon, pickup2_lat,pickup_lon, pickup_lat, dropoff_lon, dropoff_lat):\n",
    "            continue\n",
    "            \n",
    "        # decide who to drop off first \n",
    "        drop2first=not(notthearea(dropoff2_lon, dropoff2_lat,pickup2_lon, pickup2_lat, dropoff_lon, dropoff_lat))\n",
    "        drop1first=not(notthearea(dropoff_lon, dropoff_lat,pickup2_lon, pickup2_lat,dropoff2_lon, dropoff2_lat))\n",
    "        \n",
    "        # calculate corresponding distance\n",
    "        if (drop2first) | (drop1first):\n",
    "            distance1 = passenger_dis[i] + data.passenger_dis\n",
    "            if drop2first:\n",
    "                distance2 =  passenger_dis[i]\n",
    "                finished_passenger_tag[j]=1\n",
    "                return [i,j,distance1, distance2,[(pickup_lon, pickup_lat),(pickup2_lon, pickup2_lat),(dropoff2_lon, dropoff2_lat),(dropoff_lon, dropoff_lat)]]\n",
    "            else:\n",
    "                distance2 =  passenger_dis[i] + getManhattanDistance(dropoff_lon, dropoff_lat,dropoff2_lon, dropoff2_lat)\n",
    "                finished_passenger_tag[j]=1\n",
    "                return [i,j,distance1, distance2,[(pickup_lon, pickup_lat),(pickup2_lon, pickup2_lat),(dropoff_lon, dropoff_lat),(dropoff2_lon, dropoff2_lat)]]\n",
    "    \n",
    "    # if no qualified share-ride passengers, return -1, otherwise return the index of share-ride passenger\n",
    "    return [i,-1, passenger_dis[i], passenger_dis[i],[(pickup_lon, pickup_lat),(dropoff_lon, dropoff_lat)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 is ordered by pickup time\n",
    "da = df3.reset_index(drop=True)\n",
    "n = da.shape[0]\n",
    "pktime=pd.to_datetime(da['tpep_pickup_datetime'])\n",
    "\n",
    "# calculate distance of each passengers' ride \n",
    "passenger_dis=[]\n",
    "for i in da.itertuples():\n",
    "    pickup_lon, pickup_lat, dropoff_lon, dropoff_lat = [i[4],i[5],i[6],i[7]]\n",
    "    passenger_dis.append(getManhattanDistance(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon))\n",
    "da['passenger_dis']=passenger_dis\n",
    "\n",
    "# indicator for finished passengers\n",
    "finished_passenger_tag=np.zeros(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load part of the results during running of the algorithm\n",
    "import pickle\n",
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    " \n",
    "def load_variable(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  100000times: 0.2668445110321045  est time:  0.1161381583733956 mins\n",
      "100000  100000times: 295.687381029129  est time:  123.76325517216344 mins\n",
      "200000  100000times: 343.31794571876526  est time:  137.9775941356703 mins\n",
      "300000  100000times: 359.59956192970276  est time:  138.52776010979522 mins\n",
      "400000  100000times: 275.8523452281952  est time:  101.66846218503971 mins\n",
      "500000  100000times: 367.4862861633301  est time:  129.31640292630195 mins\n",
      "600000  100000times: 379.4223384857178  est time:  127.19292844883378 mins\n",
      "700000  100000times: 358.6037402153015  est time:  114.2372258540167 mins\n",
      "800000  100000times: 302.8792099952698  est time:  91.43756766191697 mins\n",
      "900000  100000times: 397.1652145385742  est time:  113.28257361820603 mins\n",
      "1000000  100000times: 430.83594965934753  est time:  115.70580528245564 mins\n",
      "1100000  100000times: 375.56788396835327  est time:  94.60348434826636 mins\n",
      "1200000  100000times: 321.5035734176636  est time:  75.62658898396127 mins\n",
      "1300000  100000times: 386.9811339378357  est time:  84.57904811144296 mins\n",
      "1400000  100000times: 399.71708846092224  est time:  80.70068171627366 mins\n",
      "1500000  100000times: 383.434531211853  est time:  71.0227474415539 mins\n",
      "1600000  100000times: 311.31719756126404  est time:  52.47599002432382 mins\n",
      "1700000  100000times: 377.0387966632843  est time:  57.27011949977124 mins\n",
      "1800000  100000times: 397.7748312950134  est time:  53.79022859055686 mins\n",
      "1900000  100000times: 388.1842534542084  est time:  46.02357797115997 mins\n",
      "2000000  100000times: 310.84508180618286  est time:  31.6734041881001 mins\n",
      "2100000  100000times: 349.6418604850769  est time:  29.79921821177872 mins\n",
      "2200000  100000times: 382.5549261569977  est time:  26.228412051404277 mins\n",
      "2300000  100000times: 380.7976779937744  est time:  19.761305100647927 mins\n",
      "2400000  100000times: 287.6332242488861  est time:  10.132695284969051 mins\n",
      "2500000  100000times: 337.88715958595276  est time:  6.271579883601467 mins\n",
      "2600000  100000times: 319.1906189918518  est time:  0.6047066276800632 mins\n",
      "[45812405.22422702, 42310479.543240584, 0.9235594450052034]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l = []\n",
    "a=time.time()\n",
    "\n",
    "for data in da.itertuples():\n",
    "    i=data[0]\n",
    "    if i%100000==0:\n",
    "        tt=time.time()-a\n",
    "        print(i,' 100000times:',tt,' est time: ', tt*(n-i)/6000000,'mins')\n",
    "        a=time.time()\n",
    "        save_variable(l,str(i)+'.txt')\n",
    "        save_variable(finished_passenger_tag,'finished_passenger_tag'+str(i))\n",
    "    if finished_passenger_tag[i]: continue\n",
    "    finished_passenger_tag[i]=1\n",
    "    tmp=find_share_rides_passenger(i)  #[-1, passenger_a, passenger_a] or [j, distance1, distance2]\n",
    "    l.append(tmp)\n",
    "n_vehicle = len(l)\n",
    "\n",
    "# total miles when not aggregate vehicles\n",
    "d_1 = 0\n",
    "# total miles when aggregate vehicles\n",
    "d_2 = 0\n",
    "\n",
    "# calculate efficiency\n",
    "for i in range(n_vehicle):\n",
    "    d_1 = l[i][2] + d_1\n",
    "    d_2 = l[i][3] + d_2\n",
    "print([d_1, d_2,d_2/d_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_variable(l,'finished.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time.txt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_variable(pktime,'time.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pktime=load_variable('time.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure how efficiency varies according to time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find slices of data during different time period\n",
    "last='2016-06-06 00:00:00'\n",
    "lst=[]\n",
    "for day in ['06','07','08','09','10','11','12']:\n",
    "    for hour in['00','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']:\n",
    "        time='2016-06-%s %s:00:00'%(day,hour)\n",
    "        if time=='2016-06-06 00:00:00':\n",
    "            continue\n",
    "        a=(pktime>=last) & (pktime<time)\n",
    "        lst.append([time,min(a[a].index),max(a[a].index)])\n",
    "        last=time\n",
    "lst.append(['2016-06-13 00:00:00',max(a[a].index)+1,len(a)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure total distance\n",
    "k=0\n",
    "oldroute=0\n",
    "newroute=0\n",
    "lll=[]\n",
    "tenk=l\n",
    "for ll in tenk:\n",
    "    if (ll[0]<=lst[k][2]) & (ll[0]>=lst[k][1]):\n",
    "        oldroute=oldroute+ll[2]\n",
    "        newroute=newroute+ll[3]\n",
    "    else:\n",
    "        lll.append([lst[k][0],oldroute,newroute,newroute/oldroute])\n",
    "        oldroute=ll[2]\n",
    "        newroute=ll[3]\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure total cars\n",
    "k=0\n",
    "totalcar=0\n",
    "totalcarnow=0\n",
    "lll=[]\n",
    "tenk=l\n",
    "for ll in tenk:\n",
    "    if (ll[0]<=lst[k][2]) & (ll[0]>=lst[k][1]):\n",
    "        totalcar=totalcar+1\n",
    "        totalcarnow=totalcarnow+1\n",
    "        if (ll[2]<ll[3]):\n",
    "            totalcar=totalcar+1\n",
    "    else:\n",
    "        lll.append([lst[k][0],totalcar,totalcarnow,totalcarnow/totalcar])\n",
    "        totalcarnow=1\n",
    "        totalcar=1\n",
    "        if (ll[2]<ll[3]):\n",
    "            totalcar=totalcar+1\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-06 01:00:00 ; 5039 ; 4997 ; 0.9916650128993848\n",
      "2016-06-06 02:00:00 ; 3314 ; 3286 ; 0.9915509957754979\n",
      "2016-06-06 03:00:00 ; 2300 ; 2277 ; 0.99\n",
      "2016-06-06 04:00:00 ; 1554 ; 1539 ; 0.9903474903474904\n",
      "2016-06-06 05:00:00 ; 1644 ; 1610 ; 0.9793187347931873\n",
      "2016-06-06 06:00:00 ; 2615 ; 2552 ; 0.9759082217973232\n",
      "2016-06-06 07:00:00 ; 6170 ; 6067 ; 0.9833063209076175\n",
      "2016-06-06 08:00:00 ; 10180 ; 10001 ; 0.9824165029469548\n",
      "2016-06-06 09:00:00 ; 11295 ; 11135 ; 0.9858344400177069\n",
      "2016-06-06 10:00:00 ; 10996 ; 10847 ; 0.9864496180429247\n",
      "2016-06-06 11:00:00 ; 9907 ; 9759 ; 0.9850610679317654\n",
      "2016-06-06 12:00:00 ; 9888 ; 9705 ; 0.9814927184466019\n",
      "2016-06-06 13:00:00 ; 10010 ; 9845 ; 0.9835164835164835\n",
      "2016-06-06 14:00:00 ; 10189 ; 10043 ; 0.9856708214741388\n",
      "2016-06-06 15:00:00 ; 10954 ; 10778 ; 0.9839328099324448\n",
      "2016-06-06 16:00:00 ; 11026 ; 10857 ; 0.9846725920551423\n",
      "2016-06-06 17:00:00 ; 10144 ; 9982 ; 0.9840299684542587\n",
      "2016-06-06 18:00:00 ; 11907 ; 11781 ; 0.9894179894179894\n",
      "2016-06-06 19:00:00 ; 14042 ; 13898 ; 0.9897450505625979\n",
      "2016-06-06 20:00:00 ; 13220 ; 13102 ; 0.9910741301059002\n",
      "2016-06-06 21:00:00 ; 11984 ; 11880 ; 0.9913217623497997\n",
      "2016-06-06 22:00:00 ; 12827 ; 12706 ; 0.9905667732127543\n",
      "2016-06-06 23:00:00 ; 11354 ; 11244 ; 0.9903117843931654\n",
      "2016-06-07 00:00:00 ; 8254 ; 8186 ; 0.9917615701478071\n",
      "2016-06-07 01:00:00 ; 5498 ; 5448 ; 0.9909057839214259\n",
      "2016-06-07 02:00:00 ; 3276 ; 3243 ; 0.98992673992674\n",
      "2016-06-07 03:00:00 ; 2046 ; 2022 ; 0.9882697947214076\n",
      "2016-06-07 04:00:00 ; 1393 ; 1384 ; 0.9935391241923905\n",
      "2016-06-07 05:00:00 ; 1357 ; 1331 ; 0.9808400884303611\n",
      "2016-06-07 06:00:00 ; 2469 ; 2413 ; 0.9773187525313892\n",
      "2016-06-07 07:00:00 ; 6287 ; 6168 ; 0.9810720534436138\n",
      "2016-06-07 08:00:00 ; 10928 ; 10772 ; 0.9857247437774525\n",
      "2016-06-07 09:00:00 ; 12283 ; 12123 ; 0.9869738663193031\n",
      "2016-06-07 10:00:00 ; 11105 ; 10965 ; 0.9873930661864025\n",
      "2016-06-07 11:00:00 ; 10363 ; 10213 ; 0.9855254269999035\n",
      "2016-06-07 12:00:00 ; 10628 ; 10472 ; 0.9853217914941663\n",
      "2016-06-07 13:00:00 ; 11347 ; 11166 ; 0.9840486472195293\n",
      "2016-06-07 14:00:00 ; 11458 ; 11249 ; 0.9817594693663816\n",
      "2016-06-07 15:00:00 ; 11714 ; 11494 ; 0.9812190541232713\n",
      "2016-06-07 16:00:00 ; 11197 ; 11013 ; 0.9835670268822005\n",
      "2016-06-07 17:00:00 ; 9518 ; 9360 ; 0.9833998739230931\n",
      "2016-06-07 18:00:00 ; 11287 ; 11135 ; 0.9865331797643306\n",
      "2016-06-07 19:00:00 ; 14362 ; 14198 ; 0.9885809775797243\n",
      "2016-06-07 20:00:00 ; 13693 ; 13556 ; 0.9899948878989264\n",
      "2016-06-07 21:00:00 ; 12763 ; 12657 ; 0.9916947426153726\n",
      "2016-06-07 22:00:00 ; 14092 ; 13959 ; 0.9905620210048255\n",
      "2016-06-07 23:00:00 ; 12966 ; 12846 ; 0.99074502545118\n",
      "2016-06-08 00:00:00 ; 10397 ; 10274 ; 0.988169664326248\n",
      "2016-06-08 01:00:00 ; 7533 ; 7431 ; 0.9864595778574273\n",
      "2016-06-08 02:00:00 ; 4779 ; 4730 ; 0.9897468089558485\n",
      "2016-06-08 03:00:00 ; 2536 ; 2518 ; 0.9929022082018928\n",
      "2016-06-08 04:00:00 ; 1684 ; 1672 ; 0.9928741092636579\n",
      "2016-06-08 05:00:00 ; 1595 ; 1559 ; 0.9774294670846395\n",
      "2016-06-08 06:00:00 ; 2575 ; 2501 ; 0.9712621359223301\n",
      "2016-06-08 07:00:00 ; 6414 ; 6293 ; 0.9811350171499844\n",
      "2016-06-08 08:00:00 ; 11253 ; 11089 ; 0.9854261085932641\n",
      "2016-06-08 09:00:00 ; 12756 ; 12574 ; 0.9857322044528065\n",
      "2016-06-08 10:00:00 ; 11818 ; 11683 ; 0.9885767473345743\n",
      "2016-06-08 11:00:00 ; 10832 ; 10656 ; 0.983751846381093\n",
      "2016-06-08 12:00:00 ; 11416 ; 11212 ; 0.9821303433777155\n",
      "2016-06-08 13:00:00 ; 13581 ; 13306 ; 0.979751122892276\n",
      "2016-06-08 14:00:00 ; 13001 ; 12753 ; 0.9809245442658258\n",
      "2016-06-08 15:00:00 ; 11538 ; 11316 ; 0.9807592303692148\n",
      "2016-06-08 16:00:00 ; 9356 ; 9162 ; 0.9792646430098333\n",
      "2016-06-08 17:00:00 ; 7202 ; 7065 ; 0.9809775062482644\n",
      "2016-06-08 18:00:00 ; 9465 ; 9330 ; 0.9857369255150554\n",
      "2016-06-08 19:00:00 ; 11719 ; 11564 ; 0.9867736154962028\n",
      "2016-06-08 20:00:00 ; 13136 ; 13003 ; 0.9898751522533495\n",
      "2016-06-08 21:00:00 ; 12790 ; 12657 ; 0.989601250977326\n",
      "2016-06-08 22:00:00 ; 14804 ; 14671 ; 0.9910159416373953\n",
      "2016-06-08 23:00:00 ; 13129 ; 12991 ; 0.9894889176631884\n",
      "2016-06-09 00:00:00 ; 11477 ; 11348 ; 0.9887601289535592\n",
      "2016-06-09 01:00:00 ; 8568 ; 8475 ; 0.9891456582633054\n",
      "2016-06-09 02:00:00 ; 4689 ; 4635 ; 0.9884836852207294\n",
      "2016-06-09 03:00:00 ; 2745 ; 2714 ; 0.9887067395264116\n",
      "2016-06-09 04:00:00 ; 1805 ; 1781 ; 0.9867036011080332\n",
      "2016-06-09 05:00:00 ; 1859 ; 1810 ; 0.9736417428725122\n",
      "2016-06-09 06:00:00 ; 2698 ; 2628 ; 0.9740548554484804\n",
      "2016-06-09 07:00:00 ; 6696 ; 6538 ; 0.9764038231780168\n",
      "2016-06-09 08:00:00 ; 11262 ; 11071 ; 0.9830403125554964\n",
      "2016-06-09 09:00:00 ; 12871 ; 12672 ; 0.984538885867454\n",
      "2016-06-09 10:00:00 ; 11889 ; 11690 ; 0.9832618386744049\n",
      "2016-06-09 11:00:00 ; 10970 ; 10797 ; 0.9842297174111212\n",
      "2016-06-09 12:00:00 ; 11083 ; 10844 ; 0.9784354416674186\n",
      "2016-06-09 13:00:00 ; 11387 ; 11135 ; 0.9778695003073681\n",
      "2016-06-09 14:00:00 ; 11314 ; 11085 ; 0.9797595898886335\n",
      "2016-06-09 15:00:00 ; 11477 ; 11206 ; 0.976387557724144\n",
      "2016-06-09 16:00:00 ; 10435 ; 10230 ; 0.9803545759463345\n",
      "2016-06-09 17:00:00 ; 8507 ; 8345 ; 0.9809568590572469\n",
      "2016-06-09 18:00:00 ; 10449 ; 10275 ; 0.9833476887740453\n",
      "2016-06-09 19:00:00 ; 12986 ; 12845 ; 0.9891421530879408\n",
      "2016-06-09 20:00:00 ; 14061 ; 13910 ; 0.9892610767370742\n",
      "2016-06-09 21:00:00 ; 13306 ; 13173 ; 0.9900045092439501\n",
      "2016-06-09 22:00:00 ; 15058 ; 14908 ; 0.9900385177314385\n",
      "2016-06-09 23:00:00 ; 13797 ; 13643 ; 0.9888381532217149\n",
      "2016-06-10 00:00:00 ; 12645 ; 12471 ; 0.9862396204033215\n",
      "2016-06-10 01:00:00 ; 10090 ; 9972 ; 0.9883052527254708\n",
      "2016-06-10 02:00:00 ; 6527 ; 6457 ; 0.989275317910219\n",
      "2016-06-10 03:00:00 ; 4301 ; 4244 ; 0.9867472680771914\n",
      "2016-06-10 04:00:00 ; 3083 ; 3029 ; 0.9824845929289653\n",
      "2016-06-10 05:00:00 ; 2483 ; 2428 ; 0.9778493757551349\n",
      "2016-06-10 06:00:00 ; 2744 ; 2672 ; 0.9737609329446064\n",
      "2016-06-10 07:00:00 ; 6226 ; 6085 ; 0.9773530356569226\n",
      "2016-06-10 08:00:00 ; 10449 ; 10251 ; 0.9810508182601206\n",
      "2016-06-10 09:00:00 ; 12274 ; 12073 ; 0.9836239204823204\n",
      "2016-06-10 10:00:00 ; 11794 ; 11596 ; 0.9832118026114973\n",
      "2016-06-10 11:00:00 ; 10634 ; 10455 ; 0.9831671995486176\n",
      "2016-06-10 12:00:00 ; 10675 ; 10459 ; 0.9797658079625293\n",
      "2016-06-10 13:00:00 ; 10826 ; 10597 ; 0.9788472196563828\n",
      "2016-06-10 14:00:00 ; 10589 ; 10354 ; 0.9778071583718954\n",
      "2016-06-10 15:00:00 ; 11325 ; 11096 ; 0.9797792494481237\n",
      "2016-06-10 16:00:00 ; 10330 ; 10145 ; 0.9820909970958374\n",
      "2016-06-10 17:00:00 ; 8882 ; 8765 ; 0.9868272911506417\n",
      "2016-06-10 18:00:00 ; 11385 ; 11260 ; 0.9890206411945542\n",
      "2016-06-10 19:00:00 ; 13630 ; 13498 ; 0.9903154805575936\n",
      "2016-06-10 20:00:00 ; 14414 ; 14270 ; 0.9900097127792424\n",
      "2016-06-10 21:00:00 ; 12869 ; 12738 ; 0.9898204988732613\n",
      "2016-06-10 22:00:00 ; 13639 ; 13518 ; 0.9911283818461764\n",
      "2016-06-10 23:00:00 ; 14200 ; 14047 ; 0.989225352112676\n",
      "2016-06-11 00:00:00 ; 13962 ; 13796 ; 0.988110585875949\n",
      "2016-06-11 01:00:00 ; 13364 ; 13176 ; 0.9859323555821611\n",
      "2016-06-11 02:00:00 ; 11158 ; 11019 ; 0.9875425703531099\n",
      "2016-06-11 03:00:00 ; 8981 ; 8842 ; 0.9845228816390157\n",
      "2016-06-11 04:00:00 ; 6750 ; 6649 ; 0.985037037037037\n",
      "2016-06-11 05:00:00 ; 4500 ; 4427 ; 0.9837777777777778\n",
      "2016-06-11 06:00:00 ; 2403 ; 2357 ; 0.9808572617561382\n",
      "2016-06-11 07:00:00 ; 3121 ; 3058 ; 0.9798141621275233\n",
      "2016-06-11 08:00:00 ; 4641 ; 4538 ; 0.9778065072182719\n",
      "2016-06-11 09:00:00 ; 6146 ; 6042 ; 0.9830784249918646\n",
      "2016-06-11 10:00:00 ; 8250 ; 8153 ; 0.9882424242424243\n",
      "2016-06-11 11:00:00 ; 9779 ; 9658 ; 0.9876265466816648\n",
      "2016-06-11 12:00:00 ; 10835 ; 10686 ; 0.9862482694970005\n",
      "2016-06-11 13:00:00 ; 11303 ; 11182 ; 0.9892948774661594\n",
      "2016-06-11 14:00:00 ; 11542 ; 11400 ; 0.987697106220759\n",
      "2016-06-11 15:00:00 ; 11181 ; 11058 ; 0.9889991950630534\n",
      "2016-06-11 16:00:00 ; 10758 ; 10657 ; 0.9906116378509017\n",
      "2016-06-11 17:00:00 ; 10170 ; 10076 ; 0.9907571288102262\n",
      "2016-06-11 18:00:00 ; 11888 ; 11807 ; 0.9931864064602961\n",
      "2016-06-11 19:00:00 ; 12705 ; 12614 ; 0.9928374655647383\n",
      "2016-06-11 20:00:00 ; 12968 ; 12865 ; 0.9920573719925971\n",
      "2016-06-11 21:00:00 ; 10934 ; 10837 ; 0.9911285897201391\n",
      "2016-06-11 22:00:00 ; 11804 ; 11713 ; 0.9922907488986784\n",
      "2016-06-11 23:00:00 ; 12729 ; 12617 ; 0.9912011941236546\n",
      "2016-06-12 00:00:00 ; 13397 ; 13243 ; 0.9885048891542882\n",
      "2016-06-12 01:00:00 ; 12251 ; 12111 ; 0.9885723614398825\n",
      "2016-06-12 02:00:00 ; 10867 ; 10721 ; 0.9865648292997148\n",
      "2016-06-12 03:00:00 ; 8820 ; 8718 ; 0.9884353741496599\n",
      "2016-06-12 04:00:00 ; 6774 ; 6680 ; 0.9861234130498967\n",
      "2016-06-12 05:00:00 ; 4563 ; 4504 ; 0.9870699101468332\n",
      "2016-06-12 06:00:00 ; 2208 ; 2171 ; 0.9832427536231884\n",
      "2016-06-12 07:00:00 ; 2283 ; 2235 ; 0.9789750328515112\n",
      "2016-06-12 08:00:00 ; 3235 ; 3160 ; 0.9768160741885626\n",
      "2016-06-12 09:00:00 ; 4855 ; 4756 ; 0.9796086508753862\n",
      "2016-06-12 10:00:00 ; 6902 ; 6771 ; 0.9810199942045784\n",
      "2016-06-12 11:00:00 ; 8642 ; 8514 ; 0.9851886137468179\n",
      "2016-06-12 12:00:00 ; 9552 ; 9405 ; 0.9846105527638191\n",
      "2016-06-12 13:00:00 ; 9992 ; 9841 ; 0.9848879103282626\n",
      "2016-06-12 14:00:00 ; 10237 ; 10080 ; 0.9846634756276252\n",
      "2016-06-12 15:00:00 ; 10154 ; 9992 ; 0.9840456962773292\n",
      "2016-06-12 16:00:00 ; 9604 ; 9458 ; 0.9847980008329863\n",
      "2016-06-12 17:00:00 ; 9662 ; 9525 ; 0.9858207410474022\n",
      "2016-06-12 18:00:00 ; 10024 ; 9891 ; 0.986731843575419\n",
      "2016-06-12 19:00:00 ; 10797 ; 10672 ; 0.9884227100120404\n",
      "2016-06-12 20:00:00 ; 10410 ; 10326 ; 0.9919308357348703\n",
      "2016-06-12 21:00:00 ; 9528 ; 9468 ; 0.9937027707808564\n",
      "2016-06-12 22:00:00 ; 9845 ; 9786 ; 0.9940071102082275\n",
      "2016-06-12 23:00:00 ; 8896 ; 8832 ; 0.9928057553956835\n"
     ]
    }
   ],
   "source": [
    "for mmm in lll:\n",
    "    print(mmm[0],';',mmm[1],';',mmm[2],';',mmm[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=load_variable('finished.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure how efficiency varies according to location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely.speedups\n",
    "from shapely.geometry import Point, Polygon\n",
    "geo_data=gpd.read_file('geo_export_ad8f6470-4f30-4869-a3e2-27a889288479.shp')\n",
    "bronx=geo_data[geo_data['boro_name']=='Bronx']['geometry'][0]\n",
    "staten_island = geo_data[geo_data['boro_name']=='Staten Island']['geometry'][1]\n",
    "queens = geo_data[geo_data['boro_name']=='Queens']['geometry'][2]\n",
    "manhattan = geo_data[geo_data['boro_name']=='Manhattan']['geometry'][3]\n",
    "brooklyn = geo_data[geo_data['boro_name']=='Brooklyn']['geometry'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide where the passenger comes from \n",
    "def find_location(x):\n",
    "    X = Point(x)\n",
    "    if X.within(manhattan): return 'Manhattan'\n",
    "    if X.within(queens): return 'Queens'\n",
    "    if X.within(brooklyn): return 'Brooklyn'\n",
    "    if X.within(bronx): return 'Bronx'\n",
    "    if X.within(staten_island): return 'Staten Island'\n",
    "    else: return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate efficiency by areas\n",
    "Bronx_noshare=0\n",
    "Bronx_share=0\n",
    "SI_noshare=0\n",
    "SI_share=0\n",
    "Queens_noshare=0\n",
    "Queens_share=0\n",
    "Manhattan_noshare=0\n",
    "Manhattan_share=0\n",
    "brooklyn_noshare=0\n",
    "brooklyn_share=0\n",
    "le=len(l)\n",
    "for ele in l:\n",
    "    index=ele[0]\n",
    "    if index%10000<5:\n",
    "        print(index)\n",
    "    ride=da.loc[index]\n",
    "    lon=ride.pickup_longitude\n",
    "    lat=ride.pickup_latitude\n",
    "    \n",
    "    # find slices of passengers' data from different area\n",
    "    area=find_location((lon,lat))\n",
    "    if area=='Bronx':\n",
    "        Bronx_noshare=Bronx_noshare+ele[2]\n",
    "        Bronx_share=Bronx_share+ele[3]\n",
    "    elif area=='Staten Island':\n",
    "        SI_noshare=SI_noshare+ele[2]\n",
    "        SI_share=SI_share+ele[3]\n",
    "    elif area=='Queens':\n",
    "        Queens_noshare=Queens_noshare+ele[2]\n",
    "        Queens_share=Queens_share+ele[3]\n",
    "    elif area=='Manhattan':\n",
    "        Manhattan_noshare=Manhattan_noshare+ele[2]\n",
    "        Manhattan_share=Manhattan_share+ele[3]\n",
    "    elif area=='Brooklyn':\n",
    "        brooklyn_noshare=brooklyn_noshare+ele[2]\n",
    "        brooklyn_share=brooklyn_share+ele[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick up area efficiency\n",
    "print('Bronx eff:',Bronx_share/Bronx_noshare,Bronx_share,Bronx_noshare)\n",
    "print('Staten Island eff:',SI_share/SI_noshare,SI_share,SI_noshare)\n",
    "print('Queens eff:',Queens_share/Queens_noshare,Queens_share,Queens_noshare)\n",
    "print('Manhattan eff:',Manhattan_share/Manhattan_noshare,Manhattan_share,Manhattan_noshare)\n",
    "print('Brooklyn eff:',brooklyn_share/brooklyn_noshare,brooklyn_share,brooklyn_noshare)\n",
    "#Bronx eff: 0.8785164473328837\n",
    "#Staten Island eff: 0.9710477606797943\n",
    "#Queens eff: 0.8649045985198403\n",
    "#Manhattan eff: 0.8867857406461953\n",
    "#Brooklyn eff: 0.901239790502349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
